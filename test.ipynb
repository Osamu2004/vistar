{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from operator import attrgetter\n",
    "from typing import List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def efficient_conv_bn_eval_forward(bn: nn.modules.batchnorm._BatchNorm,\n",
    "                                   conv: nn.modules.conv._ConvNd,\n",
    "                                   x: torch.Tensor):\n",
    "    \"\"\"Code borrowed from mmcv 2.0.1, so that this feature can be used for old\n",
    "    mmcv versions.\n",
    "\n",
    "    Implementation based on https://arxiv.org/abs/2305.11624\n",
    "    \"Tune-Mode ConvBN Blocks For Efficient Transfer Learning\"\n",
    "    It leverages the associative law between convolution and affine transform,\n",
    "    i.e., normalize (weight conv feature) = (normalize weight) conv feature.\n",
    "    It works for Eval mode of ConvBN blocks during validation, and can be used\n",
    "    for training as well. It reduces memory and computation cost.\n",
    "    Args:\n",
    "        bn (_BatchNorm): a BatchNorm module.\n",
    "        conv (nn._ConvNd): a conv module\n",
    "        x (torch.Tensor): Input feature map.\n",
    "    \"\"\"\n",
    "    # These lines of code are designed to deal with various cases\n",
    "    # like bn without affine transform, and conv without bias\n",
    "    weight_on_the_fly = conv.weight\n",
    "    if conv.bias is not None:\n",
    "        bias_on_the_fly = conv.bias\n",
    "    else:\n",
    "        bias_on_the_fly = torch.zeros_like(bn.running_var)\n",
    "\n",
    "    if bn.weight is not None:\n",
    "        bn_weight = bn.weight\n",
    "    else:\n",
    "        bn_weight = torch.ones_like(bn.running_var)\n",
    "\n",
    "    if bn.bias is not None:\n",
    "        bn_bias = bn.bias\n",
    "    else:\n",
    "        bn_bias = torch.zeros_like(bn.running_var)\n",
    "\n",
    "    # shape of [C_out, 1, 1, 1] in Conv2d\n",
    "    weight_coeff = torch.rsqrt(bn.running_var +\n",
    "                               bn.eps).reshape([-1] + [1] *\n",
    "                                               (len(conv.weight.shape) - 1))\n",
    "    # shape of [C_out, 1, 1, 1] in Conv2d\n",
    "    coefff_on_the_fly = bn_weight.view_as(weight_coeff) * weight_coeff\n",
    "\n",
    "    # shape of [C_out, C_in, k, k] in Conv2d\n",
    "    weight_on_the_fly = weight_on_the_fly * coefff_on_the_fly\n",
    "    # shape of [C_out] in Conv2d\n",
    "    bias_on_the_fly = bn_bias + coefff_on_the_fly.flatten() *\\\n",
    "        (bias_on_the_fly - bn.running_mean)\n",
    "\n",
    "    return conv._conv_forward(x, weight_on_the_fly, bias_on_the_fly)\n",
    "\n",
    "\n",
    "def efficient_conv_bn_eval_control(bn: nn.modules.batchnorm._BatchNorm,\n",
    "                                   conv: nn.modules.conv._ConvNd,\n",
    "                                   x: torch.Tensor):\n",
    "    \"\"\"This function controls whether to use `efficient_conv_bn_eval_forward`.\n",
    "\n",
    "    If the following `bn` is in `eval` mode, then we turn on the special\n",
    "    `efficient_conv_bn_eval_forward`.\n",
    "    \"\"\"\n",
    "    if not bn.training:\n",
    "        # bn in eval mode\n",
    "        output = efficient_conv_bn_eval_forward(bn, conv, x)\n",
    "        return output\n",
    "    else:\n",
    "        conv_out = conv._conv_forward(x, conv.weight, conv.bias)\n",
    "        return bn(conv_out)\n",
    "\n",
    "\n",
    "def efficient_conv_bn_eval_graph_transform(fx_model):\n",
    "    \"\"\"Find consecutive conv+bn calls in the graph, inplace modify the graph\n",
    "    with the fused operation.\"\"\"\n",
    "    modules = dict(fx_model.named_modules())\n",
    "\n",
    "    patterns = [(torch.nn.modules.conv._ConvNd,\n",
    "                 torch.nn.modules.batchnorm._BatchNorm)]\n",
    "\n",
    "    pairs = []\n",
    "    # Iterate through nodes in the graph to find ConvBN blocks\n",
    "    for node in fx_model.graph.nodes:\n",
    "        # If our current node isn't calling a Module then we can ignore it.\n",
    "        if node.op != 'call_module':\n",
    "            continue\n",
    "        target_module = modules[node.target]\n",
    "        found_pair = False\n",
    "        for conv_class, bn_class in patterns:\n",
    "            if isinstance(target_module, bn_class):\n",
    "                source_module = modules[node.args[0].target]\n",
    "                if isinstance(source_module, conv_class):\n",
    "                    found_pair = True\n",
    "        # Not a conv-BN pattern or output of conv is used by other nodes\n",
    "        if not found_pair or len(node.args[0].users) > 1:\n",
    "            continue\n",
    "\n",
    "        # Find a pair of conv and bn computation nodes to optimize\n",
    "        conv_node = node.args[0]\n",
    "        bn_node = node\n",
    "        pairs.append([conv_node, bn_node])\n",
    "\n",
    "    for conv_node, bn_node in pairs:\n",
    "        # set insertion point\n",
    "        fx_model.graph.inserting_before(conv_node)\n",
    "        # create `get_attr` node to access modules\n",
    "        # note that we directly call `create_node` to fill the `name`\n",
    "        # argument. `fx_model.graph.get_attr` and\n",
    "        # `fx_model.graph.call_function` does not allow the `name` argument.\n",
    "        conv_get_node = fx_model.graph.create_node(\n",
    "            op='get_attr', target=conv_node.target, name='get_conv')\n",
    "        bn_get_node = fx_model.graph.create_node(\n",
    "            op='get_attr', target=bn_node.target, name='get_bn')\n",
    "        # prepare args for the fused function\n",
    "        args = (bn_get_node, conv_get_node, conv_node.args[0])\n",
    "        # create a new node\n",
    "        new_node = fx_model.graph.create_node(\n",
    "            op='call_function',\n",
    "            target=efficient_conv_bn_eval_control,\n",
    "            args=args,\n",
    "            name='efficient_conv_bn_eval')\n",
    "        # this node replaces the original conv + bn, and therefore\n",
    "        # should replace the uses of bn_node\n",
    "        bn_node.replace_all_uses_with(new_node)\n",
    "        # take care of the deletion order:\n",
    "        # delete bn_node first, and then conv_node\n",
    "        fx_model.graph.erase_node(bn_node)\n",
    "        fx_model.graph.erase_node(conv_node)\n",
    "\n",
    "    # regenerate the code\n",
    "    fx_model.graph.lint()\n",
    "    fx_model.recompile()\n",
    "\n",
    "\n",
    "def turn_on_efficient_conv_bn_eval_for_single_model(model: torch.nn.Module):\n",
    "    import torch.fx as fx\n",
    "\n",
    "    # currently we use `fx.symbolic_trace` to trace models.\n",
    "    # in the future, we might turn to pytorch 2.0 compile infrastructure to\n",
    "    # get the `fx.GraphModule` IR. Nonetheless, the graph transform function\n",
    "    # can remain unchanged. We just need to change the way\n",
    "    # we get `fx.GraphModule`.\n",
    "    fx_model: fx.GraphModule = fx.symbolic_trace(model)\n",
    "    efficient_conv_bn_eval_graph_transform(fx_model)\n",
    "    model.forward = fx_model.forward\n",
    "\n",
    "\n",
    "def turn_on_efficient_conv_bn_eval(model: torch.nn.Module,\n",
    "                                   modules: Union[List[str], str]):\n",
    "    if isinstance(modules, str):\n",
    "        modules = [modules]\n",
    "    for module_name in modules:\n",
    "        module = attrgetter(module_name)(model)\n",
    "        turn_on_efficient_conv_bn_eval_for_single_model(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method SimpleCNN2.forward of SimpleCNN2(\n",
      "  (backbone): SimpleCNN(\n",
      "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): Linear(in_features=32768, out_features=10, bias=True)\n",
      "  )\n",
      ")>\n",
      "Output shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fx as fx\n",
    "\n",
    "# 定义一个简单的卷积神经网络作为示例\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.fc = nn.Linear(32 * 32 * 32, 10)  # 假设输入图像大小为32x32\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class SimpleCNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN2 ,self).__init__()\n",
    "        self.backbone = SimpleCNN()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "# 调用模型并检查优化情况\n",
    "model = SimpleCNN2()\n",
    "\n",
    "# 创建一个随机输入\n",
    "input_tensor = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "# 调用函数以启用高效的Conv + BN融合并打印优化前后的计算图\n",
    "\n",
    "\n",
    "model = model.eval()\n",
    "turn_on_efficient_conv_bn_eval(model, ['backbone'])\n",
    "print(model.forward)\n",
    "# 执行前向传播\n",
    "output = model(input_tensor)\n",
    "\n",
    "# 打印输出的形状\n",
    "print(f\"Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method forward of SimpleCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=32768, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# 检查替换后的 forward 方法\n",
    "print(model.forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    %bn1 : [num_users=1] = call_module[target=bn1](args = (%conv1,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.relu](args = (%bn1,), kwargs = {})\n",
      "    %conv2 : [num_users=1] = call_module[target=conv2](args = (%relu,), kwargs = {})\n",
      "    %bn2 : [num_users=1] = call_module[target=bn2](args = (%conv2,), kwargs = {})\n",
      "    %relu_1 : [num_users=2] = call_function[target=torch.relu](args = (%bn2,), kwargs = {})\n",
      "    %size : [num_users=1] = call_method[target=size](args = (%relu_1, 0), kwargs = {})\n",
      "    %view : [num_users=1] = call_method[target=view](args = (%relu_1, %size, -1), kwargs = {})\n",
      "    %fc : [num_users=1] = call_module[target=fc](args = (%view,), kwargs = {})\n",
      "    return fc\n"
     ]
    }
   ],
   "source": [
    "# 打印 FX 计算图\n",
    "import torch.fx as fx\n",
    "fx_model = fx.symbolic_trace(model)\n",
    "print(fx_model.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    %bn1 : [num_users=1] = call_module[target=bn1](args = (%conv1,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.relu](args = (%bn1,), kwargs = {})\n",
      "    %conv2 : [num_users=1] = call_module[target=conv2](args = (%relu,), kwargs = {})\n",
      "    %bn2 : [num_users=1] = call_module[target=bn2](args = (%conv2,), kwargs = {})\n",
      "    %relu_1 : [num_users=2] = call_function[target=torch.relu](args = (%bn2,), kwargs = {})\n",
      "    %size : [num_users=1] = call_method[target=size](args = (%relu_1, 0), kwargs = {})\n",
      "    %view : [num_users=1] = call_method[target=view](args = (%relu_1, %size, -1), kwargs = {})\n",
      "    %fc : [num_users=1] = call_module[target=fc](args = (%view,), kwargs = {})\n",
      "    return fc\n"
     ]
    }
   ],
   "source": [
    "# 打印 FX 计算图\n",
    "import torch.fx as fx\n",
    "fx_model = fx.symbolic_trace(model)\n",
    "print(fx_model.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method forward of SimpleCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=32768, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# 检查替换后的 forward 方法\n",
    "print(model.forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.4928, -0.7771, -1.0377,  ..., -0.8974, -0.3298, -0.3931],\n",
      "          [ 0.2901,  0.2581,  0.7802,  ...,  0.9171,  0.9820,  0.1806],\n",
      "          [-1.3592,  0.2125,  1.1953,  ..., -0.4506,  0.3617,  1.6183],\n",
      "          ...,\n",
      "          [-0.5671,  0.9266,  2.0484,  ..., -0.4558, -0.8388,  0.0452],\n",
      "          [ 0.0935, -0.7979,  0.9503,  ...,  0.5598, -1.9626, -0.2911],\n",
      "          [ 0.1995,  0.6507, -0.2142,  ..., -0.3146, -0.2791,  0.4547]],\n",
      "\n",
      "         [[ 1.4356,  0.9129, -0.5031,  ..., -0.1020,  1.0058, -0.4193],\n",
      "          [-1.4852, -0.4363, -0.8256,  ..., -0.9477, -0.0374,  0.1647],\n",
      "          [-0.3652, -0.2904,  2.5691,  ...,  0.5813, -0.8416, -0.9438],\n",
      "          ...,\n",
      "          [ 0.4869,  2.5273,  1.1332,  ...,  2.2675,  0.0770,  0.6853],\n",
      "          [ 0.0430, -1.8617, -0.6892,  ..., -0.8342, -0.1863, -0.8786],\n",
      "          [ 0.0802,  0.3856, -0.6600,  ...,  0.8860,  1.6499, -0.8380]],\n",
      "\n",
      "         [[-0.1324,  0.0349,  0.6080,  ..., -0.8111,  0.4878, -0.4131],\n",
      "          [-0.3960, -0.8790, -0.4031,  ..., -0.4868, -1.6179, -0.3251],\n",
      "          [-0.3331,  0.0616, -0.1891,  ...,  0.2430, -2.2637, -0.6969],\n",
      "          ...,\n",
      "          [-0.3116,  1.3042,  2.2381,  ..., -0.5227,  0.2172,  0.3950],\n",
      "          [ 0.8119, -0.1822, -0.6837,  ...,  1.7518, -0.8511, -0.4028],\n",
      "          [ 0.3381,  1.2023,  1.0385,  ...,  1.3968,  1.8621,  0.7444]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6047,  2.0174,  0.6382,  ...,  0.9876,  1.3423,  0.5428],\n",
      "          [-0.8295, -1.1071,  1.2423,  ...,  0.0537, -0.4261,  0.8158],\n",
      "          [ 0.0238,  0.0187,  0.3870,  ..., -1.4680,  0.3266, -0.0111],\n",
      "          ...,\n",
      "          [-0.3771,  0.5446,  1.8161,  ...,  0.5968, -1.2329,  0.0325],\n",
      "          [-1.0334, -0.0641, -0.1874,  ..., -0.6634, -0.6385, -0.4785],\n",
      "          [ 1.1764,  0.5247,  0.7442,  ...,  0.8770,  0.1319, -0.3058]],\n",
      "\n",
      "         [[-0.1252,  1.4410,  0.9017,  ...,  0.2556,  1.0272, -0.2598],\n",
      "          [ 0.2635,  0.9396, -0.2733,  ..., -0.3872,  1.0957, -1.3776],\n",
      "          [-0.3586,  1.7018, -0.8335,  ..., -2.0465,  1.1816,  0.5955],\n",
      "          ...,\n",
      "          [-0.5616, -0.6389, -0.8998,  ...,  0.0674, -0.1601,  1.6319],\n",
      "          [-0.4514,  0.6065, -0.5904,  ..., -0.0951, -0.4552,  1.8974],\n",
      "          [-0.2615, -1.1907, -0.3493,  ...,  0.1513, -0.8341, -0.1962]],\n",
      "\n",
      "         [[ 0.5387, -0.1873, -0.3129,  ...,  0.0514, -0.8812, -0.1566],\n",
      "          [-0.1119, -1.7238, -0.2912,  ...,  0.9898, -1.5354,  0.1751],\n",
      "          [ 0.0041,  0.1068,  0.3416,  ...,  0.0829, -1.5208, -0.6464],\n",
      "          ...,\n",
      "          [ 0.5925,  0.9936,  0.2095,  ..., -0.6645,  1.3712,  0.2904],\n",
      "          [-0.2313,  1.0972, -1.8082,  ...,  0.6864, -0.1910,  0.1683],\n",
      "          [-0.0717,  0.1626,  0.0124,  ..., -0.5204,  0.2968, -0.1452]]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output_before_fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2322, -0.3684, -0.4932,  ..., -0.4260, -0.1541, -0.1844],\n",
      "          [ 0.1428,  0.1274,  0.3775,  ...,  0.4430,  0.4741,  0.0903],\n",
      "          [-0.6471,  0.1056,  0.5763,  ..., -0.2120,  0.1770,  0.7788],\n",
      "          ...,\n",
      "          [-0.2678,  0.4476,  0.9848,  ..., -0.2145, -0.3979,  0.0255],\n",
      "          [ 0.0486, -0.3783,  0.4589,  ...,  0.2719, -0.9361, -0.1356],\n",
      "          [ 0.0993,  0.3154, -0.0988,  ..., -0.1468, -0.1298,  0.2216]],\n",
      "\n",
      "         [[ 0.8490,  0.5423, -0.2886,  ..., -0.0532,  0.5968, -0.2394],\n",
      "          [-0.8648, -0.2494, -0.4778,  ..., -0.5494, -0.0153,  0.1032],\n",
      "          [-0.2077, -0.1638,  1.5140,  ...,  0.3477, -0.4872, -0.5472],\n",
      "          ...,\n",
      "          [ 0.2923,  1.4895,  0.6715,  ...,  1.3371,  0.0518,  0.4087],\n",
      "          [ 0.0319, -1.0857, -0.3978,  ..., -0.4829, -0.1027, -0.5089],\n",
      "          [ 0.0537,  0.2329, -0.3806,  ...,  0.5265,  0.9747, -0.4851]],\n",
      "\n",
      "         [[-0.0990,  0.0130,  0.3966,  ..., -0.5533,  0.3161, -0.2869],\n",
      "          [-0.2754, -0.5987, -0.2802,  ..., -0.3362, -1.0933, -0.2280],\n",
      "          [-0.2333,  0.0309, -0.1369,  ...,  0.1523, -1.5255, -0.4768],\n",
      "          ...,\n",
      "          [-0.2189,  0.8626,  1.4877,  ..., -0.3602,  0.1350,  0.2540],\n",
      "          [ 0.5331, -0.1323, -0.4680,  ...,  1.1622, -0.5801, -0.2799],\n",
      "          [ 0.2159,  0.7944,  0.6848,  ...,  0.9246,  1.2360,  0.4879]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3908,  1.3232,  0.4129,  ...,  0.6436,  0.8776,  0.3500],\n",
      "          [-0.5557, -0.7390,  0.8117,  ...,  0.0271, -0.2895,  0.5301],\n",
      "          [ 0.0075,  0.0040,  0.2471,  ..., -0.9771,  0.2073, -0.0156],\n",
      "          ...,\n",
      "          [-0.2572,  0.3512,  1.1904,  ...,  0.3856, -0.8220,  0.0132],\n",
      "          [-0.6903, -0.0506, -0.1320,  ..., -0.4461, -0.4297, -0.3241],\n",
      "          [ 0.7682,  0.3380,  0.4829,  ...,  0.5705,  0.0788, -0.2101]],\n",
      "\n",
      "         [[-0.0906,  0.9307,  0.5790,  ...,  0.1577,  0.6609, -0.1784],\n",
      "          [ 0.1628,  0.6038, -0.1872,  ..., -0.2614,  0.7055, -0.9073],\n",
      "          [-0.2428,  1.1008, -0.5525,  ..., -1.3435,  0.7616,  0.3794],\n",
      "          ...,\n",
      "          [-0.3752, -0.4256, -0.5958,  ...,  0.0350, -0.1134,  1.0552],\n",
      "          [-0.3033,  0.3865, -0.3940,  ..., -0.0710, -0.3058,  1.2283],\n",
      "          [-0.1795, -0.7855, -0.2367,  ...,  0.0897, -0.5529, -0.1369]],\n",
      "\n",
      "         [[ 0.3335, -0.1123, -0.1895,  ...,  0.0343, -0.5384, -0.0935],\n",
      "          [-0.0660, -1.0559, -0.1761,  ...,  0.6106, -0.9402,  0.1103],\n",
      "          [ 0.0052,  0.0683,  0.2125,  ...,  0.0536, -0.9312, -0.3943],\n",
      "          ...,\n",
      "          [ 0.3666,  0.6129,  0.1314,  ..., -0.4054,  0.8448,  0.1811],\n",
      "          [-0.1393,  0.6765, -1.1078,  ...,  0.4243, -0.1146,  0.1061],\n",
      "          [-0.0413,  0.1026,  0.0103,  ..., -0.3169,  0.1850, -0.0865]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output_after_fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0116567611694336e-07\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import unittest\n",
    "from unittest import TestCase\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BackboneModel(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(6, 6, 6)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, 6, 6)\n",
    "        self.bn2 = nn.BatchNorm2d(6)\n",
    "        self.conv3 = nn.Conv2d(6, 6, 6)\n",
    "        self.bn3 = nn.BatchNorm2d(6)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # this conv-bn pair can use efficient_conv_bn_eval feature\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        # this conv-bn pair can use efficient_conv_bn_eval feature\n",
    "        # only for the second `self.conv2` call.\n",
    "        x = self.bn2(self.conv2(self.conv2(x)))\n",
    "        # this conv-bn pair can use efficient_conv_bn_eval feature\n",
    "        # just for the first forward of the `self.bn3`\n",
    "        x = self.bn3(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = BackboneModel()\n",
    "model.eval()\n",
    "input = torch.randn(64, 6, 32, 32)\n",
    "output = model(input)\n",
    "turn_on_efficient_conv_bn_eval_for_single_model(model)\n",
    "output2 = model(input)\n",
    "print((output - output2).abs().max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output before fusion:  torch.Size([1, 16, 32, 32])\n",
      "Output after fusion:  torch.Size([1, 16, 32, 32])\n",
      "Are the outputs close?  False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvBn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
    "        super(ConvBn, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.groups = groups\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "    @torch.no_grad()\n",
    "    def switch_to_deploy(self):\n",
    "        kernel = self.conv.weight\n",
    "        gamma = self.bn.weight\n",
    "        beta = self.bn.bias\n",
    "        running_mean = self.bn.running_mean\n",
    "        running_var = self.bn.running_var\n",
    "        eps = self.bn.eps\n",
    "\n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std)[:, None, None, None]\n",
    "\n",
    "        # 融合卷积权重\n",
    "        fused_conv_weight = kernel * t\n",
    "\n",
    "        # 融合卷积偏置\n",
    "        fused_conv_bias = beta - running_mean * gamma / std\n",
    "        fused_conv_bias = nn.Parameter(fused_conv_bias)\n",
    "\n",
    "        self.rbr_reparam = nn.Conv2d(self.conv.in_channels, self.conv.out_channels,\n",
    "                                      kernel_size=self.conv.kernel_size, stride=self.conv.stride,\n",
    "                                      padding=self.conv.padding, dilation=self.conv.dilation,\n",
    "                                      groups=self.conv.groups, bias=True)\n",
    "\n",
    "        self.rbr_reparam.weight.data = fused_conv_weight\n",
    "        self.rbr_reparam.bias = fused_conv_bias\n",
    "\n",
    "        del self.bn\n",
    "        del self.conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'rbr_reparam'):\n",
    "            return self.rbr_reparam(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "conv_bn_layer = ConvBn(3, 16, 3, 1, 1)\n",
    "input_tensor = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "output_before_fusion = conv_bn_layer(input_tensor)\n",
    "conv_bn_layer.switch_to_deploy()\n",
    "output_after_fusion = conv_bn_layer(input_tensor)\n",
    "\n",
    "print(\"Output before fusion: \", output_before_fusion.shape)\n",
    "print(\"Output after fusion: \", output_after_fusion.shape)\n",
    "print(\"Are the outputs close? \", torch.allclose(output_before_fusion, output_after_fusion, atol=1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vistar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
